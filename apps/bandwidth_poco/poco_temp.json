{
  "_pre_opt": "b'#include <mpmc_buffer.h>\\n#include <tapa.h>\\n#include \"bandwidth.h\"\\n#include \"sb_config.h\"\\n#include \"brahma.h\"\\n\\n\\n// using tapa::cyclic;\\n// using tapa::block;\\n// using tapa::complete;\\n// using tapa::array_partition;\\n// using tapa::memcore;\\n// using tapa::blocks;\\n// using tapa::pages;\\n// using tapa::bram;\\n\\nusing mybuf = tapa::mpmcbuffer<sb_hmsg_t[32], tapa::array_partition<tapa::block<1>>, tapa::memcore<tapa::bram>, tapa::blocks<4>, tapa::pages<8>>;\\n\\n/////////////////////////////////\\n/// MMAPS\\n/////////////////////////////////\\n\\n\\nvoid Mmap2Stream64(tapa::mmap<const uint64_t> mmap,\\n                 tapa::ostream<uint64_t>& stream,\\n                 uint32_t num_elements) {\\n  for (uint32_t i = 0; i < num_elements; ++i) {\\n    stream << mmap[i];\\n  }\\n}\\n\\nvoid Mmap2Stream32(tapa::mmap<const uint32_t> mmap,\\n                 tapa::ostream<uint32_t>& stream,\\n                 uint32_t num_elements) {\\n  for (uint32_t i = 0; i < num_elements; ++i) {\\n    stream << mmap[i];\\n  }\\n}\\n\\nvoid Stream2Mmap(tapa::istream<uint32_t>& stream,\\n                  tapa::mmap<uint32_t> mmap) {\\n  for (uint64_t i = 0; i < 1; ++i) {\\n    stream >> mmap[i];\\n  }\\n}\\n\\nvoid Stream2MmapTimer(tapa::istream<uint64_t>& stream,\\n                  tapa::mmap<uint64_t> mmap) {\\n  for (uint64_t i = 0; i < 4; ++i) {\\n    stream >> mmap[i];\\n  }\\n}\\n\\n/////////////////////////////////\\n/// TASKS\\n/////////////////////////////////\\n\\nconst uint32_t iter_looper = 1;\\nconst uint32_t page_looper = SB_NUM_PAGES/SB_NXCSRS;\\nconst uint32_t data_looper = 1;\\nconst uint32_t xctr_looper = SB_NXCTRS;\\n\\nvoid task1( tapa::istream<uint64_t>& values,\\n            tapa::istreams<ap_uint<256>, 2>& sb_rx, tapa::ostreams<ap_uint<256>, 2>& sb_tx,\\n            tapa::istreams<bool, SB_NXCTRS>& task2_to_task1,\\n            tapa::ostream<bool>& trigger_timer)\\n{\\n\\n  io_section:{\\n    #pragma HLS protocol fixed\\n\\n    // Start timer\\n    trigger_timer << 1;\\n    \\n    DEBUG_PRINT(\"[TASK1][W]: Writing...\\\\n\");\\n    \\n    uint64_t data = values.read();\\n    \\n    T1_WXCTR_LOOP: {\\n      REQ_LOOP_W0: for(uint8_t xctr = 0; xctr < xctr_looper; xctr++) {\\n      \\n      #pragma HLS unroll\\n      // DEBUG_PRINT(\"[TASK1][%d]: Iteration %d; Page %2d; Data %3d\\\\n\", xctr, i, page, d);\\n      sb_pageid_t pageid = {0};\\n      sb_dmsg_t dmsg = {{0xdeadbeef}};\\n      sb_rsp_t rsp;\\n      pageid.range(SB_PAGEID_PAGE_MSB, SB_PAGEID_PAGE_LSB) = 0;\\n      pageid.range(SB_PAGEID_XCXR_MSB, SB_PAGEID_XCXR_LSB) = xctr;  // xctr:xcsr mapping\\n      \\n        sb_req_t _req_write_0 = sb_request_write(dmsg, pageid, xctr, 1, false);\\n        sb_tx[0].write(_req_write_0);\\n      }\\n      RSP_LOOP_W0: for(uint8_t xctr = 0; xctr < xctr_looper; xctr++) {\\n        sb_rsp_t wrsp = sb_rx[0].read();\\n      }\\n    }\\n\\n    trigger_timer << 1;\\n  } // io_section\\n} // task1\\n\\nvoid task2( tapa::istreams<ap_uint<256>, 2>& sb_rx, tapa::ostreams<ap_uint<256>, 2>& sb_tx,\\n            tapa::ostreams<bool, SB_NXCTRS>& task2_to_task1)\\n{\\n  uint32_t counter[SB_NXCTRS] = {0};\\n  #pragma HLS array_partition variable=counter type=complete\\n  T2_XCTR_LOOP: {\\n    REQ_LOOP_R1: for(uint8_t xctr = 0; xctr < SB_NXCTRS; xctr++) {\\n    \\n    #pragma HLS unroll\\n    #pragma HLS latency max=0\\n    sb_pageid_t pageid = {0};\\n    pageid.range(SB_PAGEID_PAGE_MSB, SB_PAGEID_PAGE_LSB) = 0;\\n    pageid.range(SB_PAGEID_XCXR_MSB, SB_PAGEID_XCXR_LSB) = xctr;  // xctr:xcsr mapping\\n    \\n      sb_req_t _req_read_1 = sb_request_read(pageid, xctr, 1, false);\\n      sb_tx[0].write(_req_read_1);\\n    }\\n    RSP_LOOP_R1: for(uint8_t xctr = 0; xctr < SB_NXCTRS; xctr++) {\\n      sb_rsp_t data_rxsb = sb_rx[0].read();\\n    }\\n  }\\n\\n}\\n\\nvoid tick_timer(tapa::istream<bool>& rx_trigger,\\n                tapa::mmap<uint64_t> tx_timer)\\n{\\n  uint64_t time = 0;\\n  uint8_t index = 0;\\n  bool read_val, vld;\\n  for(;;)\\n  {\\n    vld = rx_trigger.try_read(read_val);\\n    if(vld)\\n    {\\n      tx_timer[index] = time;\\n      index++;\\n    }\\n    time++;\\n  }\\n}\\n\\n\\n//////////////////////\\n/// KERNEL WRAPPER ///\\n//////////////////////\\n// void bandwidth( tapa::mmap<const ap_uint<512>> ivector_values0,\\n//   tapa::mmap<const ap_uint<512>> ivector_values1,\\n//   tapa::mmap<const ap_uint<512>> ivector_values2,\\n//   tapa::mmap<const ap_uint<512>> ivector_values3,\\n//   tapa::mmap<const ap_uint<512>> ivector_values4,\\n//   tapa::mmap<const ap_uint<512>> ivector_values5,\\n//   tapa::mmap<const ap_uint<512>> ivector_values6,\\n//   tapa::mmap<const ap_uint<512>> ivector_values7,\\n//   tapa::mmap<uint64_t> ovector_timer,\\n//   tapa::mmap<uint64_t> ovector_dummy,\\n//   int dummy) {\\n\\n//////////////////////////////////////\\n/// BRAHMA: TASKS\\n//////////////////////////////////////\\n\\nconstexpr int kN = SB_NXCSRS;  // kN x kN network\\nconstexpr int kStageCount = SB_NXCSRS_LOG2;\\n\\n#ifndef SB_ARBITER_PIPE_DEPTH\\n#define SB_ARBITER_PIPE_DEPTH (1)\\n#endif\\n\\n// switch for page-->xctr arbitration\\nvoid Switch2x2(int b, tapa::istream<sb_apkt_t>& pkt_in_q0, tapa::istream<sb_apkt_t>& pkt_in_q1,\\n               tapa::ostreams<sb_apkt_t, 2>& pkt_out_q) {\\n  uint8_t priority = 0;\\n\\n  b = kStageCount - 1 - b;\\n\\n  sb_apkt_t pipe0[SB_ARBITER_PIPE_DEPTH];\\n  sb_apkt_t pipe1[SB_ARBITER_PIPE_DEPTH];\\n  \\n  for (bool valid_0, valid_1;;) {\\n    // enable the pipe here, cycling data, latency should be at the same level\\n    #pragma HLS latency max = 0\\n    // pipe0[0] = pkt_in_q0.peek(valid_0);\\n    // pipe1[0] = pkt_in_q1.peek(valid_1);\\n    // in_0 = pipe0[SB_ARBITER_PIPE_DEPTH-1];\\n    // in_1 = pipe1[SB_ARBITER_PIPE_DEPTH-1];\\n    sb_apkt_t in_0 = pkt_in_q0.peek(valid_0);\\n    sb_apkt_t in_1 = pkt_in_q1.peek(valid_1);\\n    auto pkt_0 = in_0.tag;\\n    auto pkt_1 = in_1.tag;\\n    bool fwd_0_0 = valid_0 && (pkt_0 & (1 << b)) == 0;\\n    bool fwd_0_1 = valid_0 && (pkt_0 & (1 << b)) != 0;\\n    bool fwd_1_0 = valid_1 && (pkt_1 & (1 << b)) == 0;\\n    bool fwd_1_1 = valid_1 && (pkt_1 & (1 << b)) != 0;\\n\\n    bool conflict =\\n        valid_0 && valid_1 && fwd_0_0 == fwd_1_0 && fwd_0_1 == fwd_1_1;\\n    bool prioritize_1 = priority & 1;\\n\\n    bool read_0 = !((!fwd_0_0 && !fwd_0_1) || (prioritize_1 && conflict));\\n    bool read_1 = !((!fwd_1_0 && !fwd_1_1) || (!prioritize_1 && conflict));\\n    bool write_0 = fwd_0_0 || fwd_1_0;\\n    bool write_1 = fwd_1_1 || fwd_0_1;\\n    bool write_0_0 = fwd_0_0 && (!fwd_1_0 || !prioritize_1);\\n    bool write_1_1 = fwd_1_1 && (!fwd_0_1 || prioritize_1);\\n\\n    // if can forward through (0->0 or 1->1), do it\\n    // otherwise, check for conflict\\n    const bool written_0 =\\n        write_0 && pkt_out_q[0].try_write(write_0_0 ? in_0 : in_1);\\n    const bool written_1 =\\n        write_1 && pkt_out_q[1].try_write(write_1_1 ? in_1 : in_0);\\n\\n    // if can forward through (0->0 or 1->1), do it\\n    // otherwise, round robin priority of both ins\\n    if (read_0 && (write_0_0 ? written_0 : written_1)) {\\n      pipe0[0] = pkt_in_q0.read(nullptr);\\n    }\\n    if (read_1 && (write_1_1 ? written_1 : written_0)) {\\n      pipe1[0] = pkt_in_q1.read(nullptr);\\n    }\\n\\n    if (conflict) ++priority;\\n  }\\n}\\n\\nvoid InnerStage(int b,\\n                tapa::istreams<sb_apkt_t, kN / 2>& in_q0,\\n                tapa::istreams<sb_apkt_t, kN / 2>& in_q1,\\n                tapa::ostreams<sb_apkt_t, kN> out_q) {\\n  tapa::task().invoke<tapa::detach, kN / 2>(Switch2x2, b, in_q0, in_q1, out_q);\\n}\\n\\nvoid rai(int b,\\n        tapa::istreams<sb_apkt_t, kN>& in_q,\\n        tapa::ostreams<sb_apkt_t, kN> out_q) {\\n  tapa::task().invoke<tapa::detach>(InnerStage, b, in_q, in_q, out_q);\\n}\\n\\nvoid rao(int b,\\n        tapa::istreams<sb_apkt_t, kN>& in_q,\\n        tapa::ostreams<sb_apkt_t, kN> out_q) {\\n  tapa::task().invoke<tapa::detach>(InnerStage, b, in_q, in_q, out_q);\\n}\\n\\nvoid wai(int b,\\n        tapa::istreams<sb_apkt_t, kN>& in_q,\\n        tapa::ostreams<sb_apkt_t, kN> out_q) {\\n  tapa::task().invoke<tapa::detach>(InnerStage, b, in_q, in_q, out_q);\\n}\\n\\nvoid wao(int b,\\n        tapa::istreams<sb_apkt_t, kN>& in_q,\\n        tapa::ostreams<sb_apkt_t, kN> out_q) {\\n  tapa::task().invoke<tapa::detach>(InnerStage, b, in_q, in_q, out_q);\\n}\\n\\n// Control Request Parser\\n#ifdef DEBUG_CRP\\n#define DEBUG_PRINT_CRP(...) DEBUG_PRINT(__VA_ARGS__)\\n#else\\n#define DEBUG_PRINT_CRP(...)\\n#endif\\n\\nvoid crp( tapa::istream<sb_cmsg_t>& pgm_to_crp_sts,\\n          tapa::ostream<sb_cmsg_t>& crp_to_pgm_free,\\n          tapa::ostream<sb_cmsg_t>& crp_to_pgm_grab,\\n          tapa::ostream<sb_cmsg_t>& crp_to_rsg_free,\\n          tapa::ostream<sb_cmsg_t>& crp_to_rsg_grab,\\n          tapa::istreams<sb_cmsg_t, SB_NXCTRS>& rqr_to_crp_free,\\n          tapa::istreams<sb_cmsg_t, SB_NXCTRS>& rqr_to_crp_grab) {\\n\\n  sb_portid_t xctr = 0;\\n  bool vld_free, vld_grab, vld_pgm_sts;\\n  sb_cmsg_t fwd_free, fwd_grab, pgm_rsp;\\n  for(;;)\\n  {\\n    fwd_free = rqr_to_crp_free[xctr].peek(vld_free);\\n    fwd_grab = rqr_to_crp_grab[xctr].peek(vld_grab);\\n    pgm_rsp = pgm_to_crp_sts.peek(vld_pgm_sts);\\n    if(vld_pgm_sts)\\n    {\\n      // read code and compare the lower 4 bits to check request type\\n      if((pgm_rsp.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB) & 0xF) == SB_REQ_FREE_PAGE)\\n      {\\n        crp_to_rsg_free << pgm_to_crp_sts.read();\\n        DEBUG_PRINT_CRP(\"[CRP][xctr:%2d][F]: fwd rsp --> RSG\\\\n\", pgm_rsp.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB).to_int());\\n      }\\n      else if((pgm_rsp.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB) & 0xF) == SB_REQ_GRAB_PAGE)\\n      {\\n        crp_to_rsg_grab << pgm_to_crp_sts.read();\\n        DEBUG_PRINT_CRP(\"[CRP][xctr:%2d][G]: fwd rsp --> RSG\\\\n\", pgm_rsp.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB).to_int());\\n      }\\n    }\\n    else if(vld_free)\\n    {\\n      // free request; pageid: index of page; length: xctr\\n      fwd_free.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB) = (sb_pageid_t)xctr;   // write xctr index into the index field\\n      bool w_vld_free = crp_to_pgm_free.try_write(fwd_free);\\n      if(w_vld_free)\\n      {\\n        DEBUG_PRINT_CRP(\"[CRP][xctr:%2d][F]: fwd req --> PGM\\\\n\", fwd_free.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB).to_int());\\n        rqr_to_crp_free[xctr].read();\\n      }\\n    }\\n    else if(vld_grab)\\n    {\\n      // grab request; pageid: number of pages; index of page; length: xctr\\n      fwd_grab.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB) = (sb_pageid_t)xctr;   // write xctr index into the index field\\n      bool w_vld_grab = crp_to_pgm_grab.try_write(fwd_grab);\\n      if(w_vld_grab)\\n      {\\n        DEBUG_PRINT_CRP(\"[CRP][xctr:%2d][G]: fwd req --> PGM\\\\n\", fwd_grab.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB).to_int());\\n        rqr_to_crp_grab[xctr].read();\\n      }\\n    }\\n\\n    // wrap counter from 0 to (SB_NXCTRS-1)\\n    xctr = ((xctr+1) == SB_NXCTRS) ? 0 : xctr+1;\\n  } \\n}\\n\\n\\nvoid debug_task(tapa::istreams<sb_msg_t, SB_NDEBUGQS>& debugstreams)\\n{\\n  sb_msg_t msg[SB_NDEBUGQS] = {0};\\n  for(bool valid[SB_NDEBUGQS];;)\\n  {\\n    for (int i = 0; i < SB_NDEBUGQS; i++)\\n    {\\n      msg[i] = debugstreams[i].peek(valid[i]);\\n      if(valid[i])\\n      {\\n        debugstreams[i].read();\\n      }\\n    }\\n  }\\n}\\n\\n\\n#ifdef DEBUG_DRP\\n#define DEBUG_PRINT_DRP(...) DEBUG_PRINT(__VA_ARGS__)\\n#else\\n#define DEBUG_PRINT_DRP(...)\\n#endif\\n\\n/**\\n * Task     : Data Request Parser\\n * Purpose  : The Data Request Parser is the intercept between RQR and I/OHD\\n * */\\nvoid drp(\\n        tapa::istreams<sb_std_t, SB_NXCTRS>& rqr_to_drp_read,\\n        tapa::istreams<sb_std_t, SB_NXCTRS>& rqr_to_drp_write,\\n        tapa::ostreams<sb_std_t, SB_NXCTRS>& drp_to_rsg_read,\\n        tapa::ostreams<sb_std_t, SB_NXCTRS>& drp_to_rsg_write,\\n        tapa::ostreams<sb_apkt_t, SB_NXCTRS>& drp_to_ihd_read,\\n        tapa::ostreams<sb_apkt_t, SB_NXCTRS>& drp_to_ohd_write) {\\n\\n  bool vld_rqr_w[SB_NXCTRS] = {0};\\n  bool vld_rqr_r[SB_NXCTRS] = {0};\\n  bool burst_done[SB_NXCTRS];\\n  bool skid_read[SB_NXCTRS];\\n  sb_pageid_t pageid[SB_NXCTRS] = {0};\\n  uint8_t burst_size[SB_NXCTRS] = {0};\\n  uint8_t xcsrid[SB_NXCSRS] = {0};\\n  sb_apkt_t w_fwd_req[SB_NXCTRS];\\n  uint8_t tags[SB_NXCSRS][SB_PAGES_PER_XCSR] = {0};\\n  // ap_uint<SB_TAG_WIDTH> tags[SB_NXCSRS][SB_PAGES_PER_XCSR] =  {0};\\n  #pragma HLS array_partition variable=vld_rqr_r type=complete\\n  #pragma HLS array_partition variable=vld_rqr_w type=complete\\n\\n  enum drp_writestate_e {BURST_START=0, BURST_CONT, BURST_STOP};\\n  drp_writestate_e cs_w[SB_NXCTRS], ns_w[SB_NXCTRS];\\n\\n  DRP_INIT: for(sb_portid_t xctr = 0; xctr < SB_NXCTRS; xctr++)\\n  {\\n    burst_done[xctr] = true;\\n    skid_read[xctr] = false;\\n    cs_w[xctr] = BURST_START;\\n    ns_w[xctr] = BURST_START;\\n  }\\n\\n  DRP_LOOP: for(;;)\\n  {\\n    #pragma HLS latency max=0\\n    for(sb_portid_t xctr = 0; xctr < SB_NXCTRS; xctr++)\\n    {\\n      #pragma HLS unroll\\n      vld_rqr_w[xctr] = rqr_to_drp_write[xctr].try_peek(w_fwd_req[xctr].msg);\\n      if(vld_rqr_w[xctr]/* && burst_done[xctr]*/) {               // new write request\\n        // prepare for burst\\n        xcsrid[xctr] = w_fwd_req[xctr].msg.control.range(SB_CMSG_XCXR_MSB, SB_CMSG_XCXR_LSB);     // extract the xcsr from the pageid\\n        pageid[xctr] = w_fwd_req[xctr].msg.control.range(SB_CMSG_PAGEID_MSB, SB_CMSG_PAGEID_LSB); // extract the full pageid\\n        \\n        // set arbiter-pkt\\'s tag to the xcsr to route this packet to relevant I/OHD\\n        w_fwd_req[xctr].tag = xcsrid[xctr];\\n        // swap xcsr information in packet with xctr information\\n        w_fwd_req[xctr].msg.control.range(SB_CMSG_XCXR_MSB, SB_CMSG_XCXR_LSB) = xctr;\\n\\n        const bool written_w = !drp_to_rsg_write[xctr].full() && !drp_to_ohd_write[xctr].full();\\n        if(written_w)\\n        {\\n          DEBUG_PRINT_DRP(\"[DRP][xctr:%2d][W]: fwd packet\\\\n\", xctr);\\n          drp_to_rsg_write[xctr] << w_fwd_req[xctr].msg;              // ctrl pkt for RSG to track\\n          drp_to_ohd_write[xctr] << w_fwd_req[xctr];                  // control packet for OHD to track\\n          rqr_to_drp_write[xctr].read(nullptr);\\n        }\\n      }\\n\\n      // READS\\n      sb_apkt_t r_fwd_req;\\n      r_fwd_req.msg = rqr_to_drp_read[xctr].peek(vld_rqr_r[xctr]);\\n      // 1. swap xcsr information with xctr information\\n      // 1.1 route this packet to relevant I/OHD\\n      r_fwd_req.tag = r_fwd_req.msg.control.range(SB_CMSG_XCXR_MSB, SB_CMSG_XCXR_LSB);\\n      // 1.2 make the pageid field store the `xctr` value so that it can be routed back to RSG\\n      r_fwd_req.msg.control.range(SB_CMSG_XCXR_MSB, SB_CMSG_XCXR_LSB) = xctr;                \\n      if(vld_rqr_r[xctr])\\n      {\\n        uint8_t msgs = r_fwd_req.msg.control.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB);  // TODO: doesn\\'t look like `msgs` or `nb_fwd_req`  need to be created as an array because it is internal to the loop\\n        // DEBUG_PRINT_DRP(\"[DRP][xctr:%2d][R]: req.nmsgs:%2d\\\\n\", xctr, msgs);\\n        drp_to_ihd_read[xctr] << r_fwd_req;  // for data\\n        DEBUG_PRINT_DRP(\"[DRP][xctr:%2d][R]: fwd req --> IHD\\\\n\", xctr);\\n        drp_to_rsg_read[xctr] << r_fwd_req.msg;  // for RSG to track\\n        DEBUG_PRINT_DRP(\"[DRP][xctr:%2d][R]: fwd req --> RSG\\\\n\", xctr);\\n        r_fwd_req.msg = rqr_to_drp_read[xctr].read();\\n      }\\n    }\\n  }\\n}\\n\\n#ifdef DEBUG_IHD\\n#define DEBUG_PRINT_IHD(...) DEBUG_PRINT(__VA_ARGS__)\\n#else\\n#define DEBUG_PRINT_IHD(...)\\n#endif\\n\\n\\n/**\\n * Task     : I/OHD\\n * Purpose  : The IOHD is responsible for the grunt work of the data transfer\\n *              related to the requests. The input and output streams\\n *              from RQP and to RSG will later be widened based on NRX and NTX,\\n *              allowing multiple requests to be parsed in parallel.\\n *              THIS PATH MUST BE OPTIMISED FOR PERFORMANCE.\\n *\\n*/\\nvoid ihd(int seq,\\n        tapa::istream<sb_apkt_t>& rai_to_ihd_read,\\n        tapa::ostream<sb_apkt_t>& ihd_to_rao_read,\\n        tapa::ibuffers<sb_hmsg_t[SB_WORDS_PER_PAGE], (SB_PAGES_PER_XCSR), 1, tapa::array_partition<tapa::block<SB_NUM_PARTITIONS>>, tapa::memcore<tapa::bram>>& backend_pages) {\\n\\n  bool burst_done=true, rsp_done=true, valid=false, xfer_ctrl_valid=false;\\n  //#ifndef __SYNTHESIS__\\n  sb_dmsg_t msgdata = {0};\\n  //#endif\\n  sb_portid_t xctrid;\\n  uint8_t pageid, nmsgs, msgs_txed, last_pageid = 0xFF;\\n  uint16_t start_index = 0;\\n  sb_apkt_t req, rsp;\\n  uint8_t code;\\n  bool last_buffer_released = true, pause_read_for_buffer_release = false, written = true;\\n\\n  IHD_MAIN: for(;;)\\n  {\\n    #pragma HLS latency max=0\\n    if(written)\\n    {\\n      valid = rai_to_ihd_read.try_read(req);\\n    }\\n\\n    //DEBUG_PRINT(\"[IHD][xctr:%2d][R]: Repeat %d %d %d %d\\\\n\", xctr, valid[xctr], req[xctr].c_dn, burst_done[xctr], rsp_done[xctr]);\\n    if(valid)\\n    {\\n      code         = req.msg.control.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB);       // get the code\\n      nmsgs        = req.msg.control.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB);   // get number of messages to read\\n      start_index  = req.msg.control.range(SB_CMSG_ADDR_MSB, SB_CMSG_ADDR_LSB);       // get starting index of where to read from\\n      xctrid       = req.msg.control.range(SB_CMSG_XCXR_MSB, SB_CMSG_XCXR_LSB);       // extract the xctrid from pageid field\\n      pageid       = req.msg.control.range(SB_CMSG_PAGE_MSB, SB_CMSG_PAGE_LSB);       // store pageid to access\\n      // DEBUG_PRINT_IHD(\"[IHD][xcsr:%2d][R]: xctr: %d, addr: %d, nmsgs: %d\\\\n\", seq, req.tag, start_index, nmsgs);\\n      rsp.msg.control = req.msg.control;                // store the req ctrl pkt in the rsp ctrl pkt, modify it along the way\\n      // printf(\"[IHD][xcsr:%2d][D] pageid : %d\\\\n\", seq, pageid);\\n      assert(pageid < SB_PAGES_PER_XCSR);\\n\\n      if(last_buffer_released)\\n      {\\n        DEBUG_PRINT_IHD_BUFF(\"[IHD][xcsr:%2d][T]: Acquiring Buffer\\\\n\", seq);\\n        auto section = backend_pages[pageid].create_section();\\n        backend_pages[pageid].acquire(section);\\n        last_pageid = pageid;\\n        last_buffer_released = false;\\n        written = false;\\n      }\\n      else\\n      {\\n        // get the pageref\\n        auto& page_ref = (backend_pages[pageid].create_section())();\\n        // rsp.msg.std_msg = page_ref[msgs_txed];\\n        // prefetch stuff into the 0th index\\n        uint16_t access_index = 2*start_index;\\n        for(uint16_t i = 0; i < SB_NUM_PARTITIONS; i++)\\n        {\\n          #pragma HLS unroll\\n          sb_hmsg_t var0 = page_ref[i*(SB_WORDS_PER_PAGE/SB_NUM_PARTITIONS) + access_index+0];\\n          sb_hmsg_t var1 = page_ref[i*(SB_WORDS_PER_PAGE/SB_NUM_PARTITIONS) + access_index+1];\\n          msgdata.msg[i] = ((sb_msg_t)var1 << SB_HMSG_W) | var0;\\n        }\\n\\n        // set code\\n        rsp.msg.control.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB) = SB_RSP_DONE | code;\\n        // patch back the index of the xcsr\\n        rsp.msg.control.range(SB_CMSG_XCXR_MSB, SB_CMSG_XCXR_LSB) = seq;\\n        // update tag with the xctrid for rerouting back to RSG\\n        rsp.tag         = xctrid;\\n        // try writing this data\\n        rsp.msg.std_msg = msgdata;\\n        written = ihd_to_rao_read.try_write(rsp);\\n        // DEBUG_PRINT_IHD(\"[IHD][xcsr:%2d][R]: Sent message (%d): %lx %x %x\\\\n\", seq, msgs_txed, (uint64_t)msgdata[prefetch_index], (uint32_t)var1[prefetch_index], (uint32_t)var0[prefetch_index]);\\n\\n        if(written)\\n        {\\n          // sb_apkt_t nc;\\n          // rai_to_ihd_read.try_read(nc); // this read will always succeed since there must be data to reach, we just want to consume the token with II=1\\n          // last_token_consumed = true;\\n          DEBUG_PRINT_IHD(\"[IHD][xcsr:%2d][R]: xctr: %d, pageid: %d, addr: %d\\\\n\", seq, xctrid, pageid, start_index);\\n          // DEBUG_PRINT_IHD(\"[IHD][xcsr:%2d][R]: Message: %lx\\\\n\", seq, (uint64_t)msgdata.msg[0]);\\n          // DEBUG_PRINT_IHD(\"[IHD][xcsr:%2d][R]: Message: %lx %x %x\\\\n\", seq, (uint64_t)msgdata.msg[0], page_ref[2*(start_index + msgs_rxed)], page_ref[2*(start_index + msgs_rxed)+1]);\\n        }\\n\\n        if(code & SB_RW_CONT_MASK)          // if this is a continued transaction\\n        {                                   // request control again\\n          // DEBUG_PRINT_IHD(\"[IHD][xcsr:%2d][T]: Continued-read flag set\\\\n\", seq);\\n          last_buffer_released = false;\\n        } else {                            // else release buffer\\n          DEBUG_PRINT_IHD_BUFF(\"[IHD][xcsr:%2d][T]: Releasing Buffer\\\\n\", seq);\\n          (backend_pages[pageid].create_section()).release_section();\\n          last_buffer_released = true;\\n        }\\n      }\\n    }\\n  }\\n}\\n\\n#ifdef DEBUG_PGM\\n#define DEBUG_PRINT_PGM(...) DEBUG_PRINT(__VA_ARGS__)\\n#else\\n#define DEBUG_PRINT_PGM(...)\\n#endif\\n\\n// Function to find the index of the first 0 bit in a number\\ninline uint8_t find_first_zero_bit_index(uint8_t num) {\\n  for (uint8_t i = 0; i < 8; i++) {\\n    if (!(num & (1 << i))) {\\n      return i;\\n    }\\n  }\\n  return 0xFF;  // error code\\n}\\n\\nuint8_t byte_lut[255] = {\\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 4, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 5, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 4, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 6, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 4, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 5, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 4, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 7, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 4, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 5, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 4, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 6, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 4, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 5, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0, 4, \\n0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0,};\\n\\n/**\\n * Task     : Page Manager\\n * Purpose  : The page-manager is responsible for maintaining all information\\n *              related to the page allocation/deallocations\\n *              THIS PATH IS NOT OPTIMISED FOR PERFORMANCE.\\n *\\n*/\\nvoid pgm(tapa::istream<sb_cmsg_t>& rqp_to_pgm_grab,\\n        tapa::istream<sb_cmsg_t>& rqp_to_pgm_free,\\n        tapa::ostream<sb_cmsg_t>& pgm_to_rqp_sts) {\\n\\n  // sb_metadata_t metadata[SB_NUM_PAGES] = {0};\\n  uint8_t valid[(SB_NUM_PAGES>>3) ? (SB_NUM_PAGES>>3) : 8] = {0};\\n\\n  // sb_metadata_t free_md, grab_md;\\n  uint16_t free_vld8_pre, free_vld8_new, free_pageid_in8;\\n  uint16_t grab_vld8_pre, grab_vld8_new, grab_pageid_in8, grab_avl_idx;\\n  bool grab_avl;\\n  sb_cmsg_t fwd_rsp_f, fwd_rsp_g, rsp;\\n  uint16_t grab_pageid;\\n  uint16_t free_pageid;\\n\\n  // initialise lookup array\\n  uint8_t avl_page_lut[255] = {0};\\n  for (uint8_t i = 0; i < 255; i++)\\n  {\\n    avl_page_lut[i] = find_first_zero_bit_index(i);\\n  }\\n\\n  for(bool vld_g, vld_f;;)\\n  {\\n    // clear existing response\\n    // rsp.c_dn = 1;\\n    rsp = 0;\\n    fwd_rsp_f = rqp_to_pgm_free.peek(vld_f);\\n    fwd_rsp_g = rqp_to_pgm_grab.peek(vld_g);\\n    if(vld_f)       // handle page deallocation\\n    {\\n      DEBUG_PRINT_PGM(\"[PGM][xctr:%2d][F]: pageid %d\\\\n\", fwd_rsp_f.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB).to_int(), fwd_rsp_f.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB).to_int());\\n      \\n      // update page info\\n      free_pageid     = fwd_rsp_f.range(SB_CMSG_PAGEID_MSB, SB_CMSG_PAGEID_LSB);\\n      free_vld8_pre   = valid[free_pageid>>3];                      // get the 8-bit valid byte\\n      free_pageid_in8 = free_pageid & 0x7;                          // get the 3LSBs from `pageid`\\n      free_vld8_new   = free_vld8_pre & ~(1 << free_pageid_in8);    // unset this specific bit\\n      valid[free_pageid>>3] = free_vld8_new;\\n\\n      // send response\\n      rsp.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB)   = SB_RSP_DONE | SB_REQ_FREE_PAGE;\\n      rsp.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB)  = fwd_rsp_f.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB);\\n      pgm_to_rqp_sts << rsp;\\n\\n      rqp_to_pgm_free.read(); // consume the token\\n\\n      DEBUG_PRINT_PGM(\"[PGM][xctr:%2d][F]: fwd rsp --> RQP\\\\n\", rsp.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB).to_int());\\n    }\\n\\n    else if(vld_g)  // handle page allocation\\n    {\\n      DEBUG_PRINT_PGM(\"[PGM][xctr:%2d][G]: %d page(s)\\\\n\", fwd_rsp_g.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB).to_int(), fwd_rsp_g.range(SB_CMSG_PAGEID_MSB, SB_CMSG_PAGEID_LSB).to_int());\\n\\n      grab_avl = false;\\n      // loop around all bytes and find the available index\\n      PGM_G_BIN_SEARCH: for(uint16_t i = 0; i < (SB_NUM_PAGES>>3); i++) {\\n        if(valid[i] != 0xFF) {\\n          grab_avl_idx = i;\\n          grab_avl = true;\\n          break;\\n        }\\n      }\\n      if(grab_avl)\\n      {\\n        // update page info\\n        grab_vld8_pre   = valid[grab_avl_idx];                        // get the 8-bit valid byte\\n        grab_pageid_in8 = avl_page_lut[grab_vld8_pre];                // find a page which is keeping the bin empty\\n        grab_vld8_new   = grab_vld8_pre | (1 << grab_pageid_in8);     // set this specific bit\\n        valid[grab_avl_idx] = grab_vld8_new;\\n\\n        grab_pageid     = (grab_avl_idx << 3) | grab_pageid_in8;      // form the pageid\\n        rsp.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB) = SB_RSP_DONE | SB_REQ_GRAB_PAGE;\\n        rsp.range(SB_CMSG_PAGEID_MSB, SB_CMSG_PAGEID_LSB) = grab_pageid;\\n      }\\n      else\\n      {\\n        // generate the response\\n        rsp.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB) = SB_RSP_FAIL | SB_REQ_GRAB_PAGE;\\n        // hardcoded to return bad pageid\\n        rsp.range(SB_CMSG_PAGEID_MSB, SB_CMSG_PAGEID_LSB) = 0xFFFF;\\n      }\\n\\n      // finalise grab request and send it\\n      rsp.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB) = fwd_rsp_g.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB);\\n      pgm_to_rqp_sts << rsp;\\n      // consume the token\\n      rqp_to_pgm_grab.read();\\n\\n      DEBUG_PRINT_PGM(\"[PGM][xctr:%2d][G]: fwd rsp --> RQP\\\\n\", rsp.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB));\\n    }\\n    else {}\\n  }\\n}\\n\\n#ifdef DEBUG_RQR\\n#define DEBUG_PRINT_RQR(...) DEBUG_PRINT(__VA_ARGS__)\\n#else\\n#define DEBUG_PRINT_RQR(...)\\n#endif\\n\\n// Request Router\\nvoid rqr(tapa::istreams<sb_req_t, SB_NXCTRS>& brxqs,\\n        tapa::ostreams<sb_cmsg_t, SB_NXCTRS>& rqr_to_rqp_grab,\\n        tapa::ostreams<sb_cmsg_t, SB_NXCTRS>& rqr_to_rqp_free,\\n        tapa::ostreams<sb_std_t, SB_NXCTRS>& rqr_to_rqp_read,\\n        tapa::ostreams<sb_std_t, SB_NXCTRS>& rqr_to_rqp_write) {\\n\\n  bool valid[SB_NXCTRS];\\n  bool fwd_rqp_free[SB_NXCTRS];\\n  bool fwd_rqp_grab[SB_NXCTRS];\\n  bool fwd_rqp_read[SB_NXCTRS];\\n  bool fwd_rqp_write[SB_NXCTRS];\\n  bool burst_done[SB_NXCTRS];\\n  bool skid_read[SB_NXCTRS];\\n  bool written_f = false, written_g = false, written_r = false, written_w = false;\\n  uint8_t burst_size[SB_NXCTRS] = {0};\\n  sb_req_t req[SB_NXCTRS];\\n  sb_std_t std_req[SB_NXCTRS];\\n  bool c_dn[SB_NXCTRS]; uint8_t code[SB_NXCTRS];\\n\\n  #pragma HLS array_partition variable=fwd_rqp_free type=complete\\n  #pragma HLS array_partition variable=fwd_rqp_grab type=complete\\n  #pragma HLS array_partition variable=fwd_rqp_read type=complete\\n  #pragma HLS array_partition variable=fwd_rqp_write type=complete\\n  #pragma HLS array_partition variable=skid_read type=complete\\n  #pragma HLS array_partition variable=burst_done type=complete\\n  #pragma HLS array_partition variable=burst_size type=complete\\n  #pragma HLS array_partition variable=req type=complete\\n  #pragma HLS array_partition variable=std_req type=complete\\n\\n  RQR_INIT: for(sb_portid_t xctr = 0; xctr < SB_NXCTRS; xctr++)\\n  {\\n    burst_done[xctr] = true;\\n    skid_read[xctr] = false;\\n  }\\n\\n  RQR_LOOP: for(;;)\\n  {\\n    #pragma HLS latency max = 0\\n    for(uint8_t xctr = 0; xctr < SB_NXCTRS; xctr++) // this check is being done for each xctr stream being rxed\\n    {\\n      #pragma HLS unroll    // full unroll by a factor of SB_NXCTRS\\n      // try reading whether value is available only if the previous value is read already\\n      req[xctr] = brxqs[xctr].peek(valid[xctr]);\\n      code[xctr] = req[xctr].control.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB);\\n      c_dn[xctr] = req[xctr].c_dn;\\n      fwd_rqp_free[xctr]  = valid[xctr] && ( code[xctr] == SB_REQ_FREE_PAGE);\\n      fwd_rqp_grab[xctr]  = valid[xctr] && ( code[xctr] == SB_REQ_GRAB_PAGE);\\n      fwd_rqp_read[xctr]  = valid[xctr] && ((code[xctr] & SB_RW_MASK) == SB_REQ_READ_S) ;   // lower two bits signify R/W\\n      fwd_rqp_write[xctr] = valid[xctr] && ((code[xctr] & SB_RW_MASK) == SB_REQ_WRITE_S);   // lower two bits signify R/W\\n\\n      std_req[xctr] = req_to_std(req[xctr]);\\n\\n      const bool written_f =  fwd_rqp_grab[xctr] && rqr_to_rqp_free[xctr].try_write(std_req[xctr].control);\\n      const bool written_g =  fwd_rqp_grab[xctr] && rqr_to_rqp_grab[xctr].try_write(std_req[xctr].control);\\n      const bool written_r =  fwd_rqp_read[xctr] && rqr_to_rqp_read[xctr].try_write(std_req[xctr]);\\n      const bool written_w = fwd_rqp_write[xctr] && rqr_to_rqp_write[xctr].try_write(std_req[xctr]);\\n      if((written_f || written_g || written_r || written_w) && valid[xctr])\\n      {\\n        brxqs[xctr].read(nullptr);\\n      }\\n\\n      #ifndef __SYNTHESIS__\\n      if(valid[xctr])\\n      {\\n        if(written_f) {\\n          DEBUG_PRINT_RQR(\"[RQR][F]: Page: %x\\\\n\", std_req[xctr].control.range(SB_CMSG_PAGEID_MSB, SB_CMSG_PAGEID_LSB));\\n        } else if(written_g) {\\n          DEBUG_PRINT_RQR(\"[RQR][G]: Page: %x\\\\n\", std_req[xctr].control.range(SB_CMSG_PAGEID_MSB, SB_CMSG_PAGEID_LSB));\\n        } else if(written_w) {\\n          DEBUG_PRINT_RQR(\"[RQR][W]: Address: %x, Data: %lx\\\\n\", std_req[xctr].control.range(SB_CMSG_ADDR_MSB, SB_CMSG_ADDR_LSB).to_int(), std_req[xctr].std_msg.msg[0]);\\n        } else if(written_r) {\\n          DEBUG_PRINT_RQR(\"[RQR][R]: Address: %x, Data: %lx\\\\n\", std_req[xctr].control.range(SB_CMSG_ADDR_MSB, SB_CMSG_ADDR_LSB).to_int(), std_req[xctr].std_msg.msg[0]);\\n        }\\n      }\\n      #endif\\n    }\\n  }\\n}\\n\\n#ifdef DEBUG_RSG\\n#define DEBUG_PRINT_RSG(...) DEBUG_PRINT(__VA_ARGS__)\\n#else\\n#define DEBUG_PRINT_RSG(...)\\n#endif\\n\\nvoid rsg(tapa::istream<sb_cmsg_t>& rqp_to_rsg_grab,\\n        tapa::istream<sb_cmsg_t>& rqp_to_rsg_free,\\n        tapa::istreams<sb_std_t, SB_NXCTRS>& rqp_to_rsg_read,\\n        tapa::istreams<sb_std_t, SB_NXCTRS>& rqp_to_rsg_write,\\n        tapa::istreams<sb_apkt_t, SB_NXCTRS>& ihd_to_rsg_read,\\n        tapa::istreams<sb_apkt_t, SB_NXCTRS>& ohd_to_rsg_write,\\n        tapa::ostreams<sb_rsp_t, SB_NXCTRS>& btxqs) {\\n\\n  // Free > Grab > Read > Write\\n  sb_std_t  f_fwd_rsp = {0}, g_fwd_rsp = {0};\\n  sb_std_t  rc_fwd_rsp[SB_NXCTRS], wc_fwd_rsp[SB_NXCTRS];\\n  sb_apkt_t rd_fwd_rsp[SB_NXCTRS], wd_fwd_rsp[SB_NXCTRS];\\n  bool vld_rsg_g, vld_rsg_f;\\n  bool vld_rsg_rc[SB_NXCTRS], vld_rsg_rd[SB_NXCTRS], burst_done[SB_NXCTRS];\\n  bool vld_rsg_wc[SB_NXCTRS], vld_rsg_wd[SB_NXCTRS];\\n  uint8_t burst_size[SB_NXCTRS] = {0};\\n  //#pragma HLS array_partition variable=r_fwd_rsp  type=complete\\n  //#pragma HLS array_partition variable=w_fwd_rsp  type=complete\\n  //#pragma HLS array_partition variable=vld_rsg_r  type=complete\\n  //#pragma HLS array_partition variable=vld_rsg_w  type=complete\\n  //#pragma HLS array_partition variable=burst_size type=complete\\n  //#pragma HLS array_partition variable=burst_done type=complete\\n  //#pragma HLS array_partition variable=skid_read  type=complete\\n\\n  RSG_INIT: for(sb_portid_t xctr = 0; xctr < SB_NXCTRS; xctr++)\\n  {\\n    burst_done[xctr] = true;\\n  }\\n\\n  // // peek       --> r_pvld + r_data\\n  // // try_write  --> w_tvld\\n  // // read       <-- if(w_tvld)\\n\\n  // rvld = istream.try_peek(data);\\n  // if(rvld)\\n  //   wvld = ostream.try_write(w_tvld);\\n  // else\\n  //   wvld = false;\\n  // if(wvld)\\n  //   istream.read(nullptr);\\n\\n  bool cons_free = false, cons_grab = false;\\n\\n  RSG_LOOP: for(;;)\\n  {\\n    #pragma HLS latency max=0\\n    vld_rsg_f = rqp_to_rsg_free.try_peek(f_fwd_rsp.control);\\n    vld_rsg_g = rqp_to_rsg_grab.try_peek(g_fwd_rsp.control);\\n\\n    // TODO: usage of this must be fixed later. Current assumption is that DP is prioritised higher than CP\\n    // at the task level, so no data transactions are pending before a control request on a xctr is issued.\\n    cons_free = false;\\n    cons_grab = false;\\n    for(sb_portid_t xctr = 0; xctr < SB_NXCTRS; xctr++)\\n    {\\n      #pragma HLS unroll\\n      // if(!skid_read[xctr]) { vld_rsg_r[xctr] = rqp_to_rsg_read[xctr].try_read(r_fwd_rsp[xctr]);\\n      vld_rsg_wc[xctr] = (rqp_to_rsg_write[xctr].try_peek(wc_fwd_rsp[xctr]));\\n      vld_rsg_wd[xctr] = (ohd_to_rsg_write[xctr].try_peek(wd_fwd_rsp[xctr]));\\n      vld_rsg_rc[xctr] = (rqp_to_rsg_read[xctr].try_peek(rc_fwd_rsp[xctr]));\\n      vld_rsg_rd[xctr] = (ihd_to_rsg_read[xctr].try_peek(rd_fwd_rsp[xctr]));\\n\\n      const bool vld_free_pkt  = (vld_rsg_f && ((sb_portid_t)f_fwd_rsp.control.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB) == xctr));\\n      const bool vld_grab_pkt  = (vld_rsg_g && ((sb_portid_t)g_fwd_rsp.control.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB) == xctr));\\n      const bool vld_read_pkt  = (vld_rsg_rd[xctr] && vld_rsg_rc[xctr]);\\n      const bool vld_write_pkt = (vld_rsg_wd[xctr] && vld_rsg_wc[xctr]);\\n      const bool vld_fwd = !btxqs[xctr].full();\\n\\n      if(vld_fwd && vld_read_pkt)             // READS\\n      {\\n        btxqs[xctr].try_write(std_to_rsp(rd_fwd_rsp[xctr].msg));  // this try_write must succeed since its guarded with vld_fwd\\n        sb_std_t nc_rc; sb_apkt_t nc_rd;\\n        rqp_to_rsg_read[xctr].try_read(nc_rc);\\n        ihd_to_rsg_read[xctr].try_read(nc_rd);\\n        DEBUG_PRINT_RSG(\"[RSG][xctr:%2d][R]: TX response\\\\n\", xctr);\\n      }\\n      else if(vld_fwd && vld_write_pkt)       // WRITES\\n      {\\n        btxqs[xctr].try_write(std_to_rsp(wd_fwd_rsp[xctr].msg));\\n        sb_std_t nc_wc; sb_apkt_t nc_wd;\\n        rqp_to_rsg_write[xctr].try_read(nc_wc);\\n        ohd_to_rsg_write[xctr].try_read(nc_wd);\\n        DEBUG_PRINT_RSG(\"[RSG][xctr:%2d][W]: TX response\\\\n\", xctr);\\n      }\\n      else if(vld_fwd && vld_free_pkt)        // FREE\\n      {\\n        cons_free |= true;\\n        btxqs[xctr].try_write(std_to_rsp(f_fwd_rsp));\\n        DEBUG_PRINT_RSG(\"[RSG][xctr:%2d][F]: TX response\\\\n\", xctr);\\n      }\\n      else if(vld_fwd && vld_grab_pkt)        // GRAB\\n      {\\n        cons_grab |= true;\\n        btxqs[xctr].try_write(std_to_rsp(g_fwd_rsp));\\n        DEBUG_PRINT_RSG(\"[RSG][xctr:%2d][G]: TX response\\\\n\", xctr);\\n      }\\n      else{}\\n    }\\n    if(cons_free)\\n    {\\n      sb_cmsg_t nc_free;\\n      rqp_to_rsg_free.try_read(nc_free);\\n    }\\n    if(cons_grab)\\n    {\\n      sb_cmsg_t nc_grab;\\n      rqp_to_rsg_grab.try_read(nc_grab);\\n    }\\n  }\\n}\\n\\n#ifdef DEBUG_OHD\\n#define DEBUG_PRINT_OHD(...) DEBUG_PRINT(__VA_ARGS__)\\n#else\\n#define DEBUG_PRINT_OHD(...)\\n#endif\\n\\n/**\\n * Task     : I/OHD\\n * Purpose  : The IOHD is responsible for the grunt work of the data transfer\\n *              related to the requests. The input and output streams\\n *              from RQP and to RSG will later be widened based on NRX and NTX,\\n *              allowing multiple requests to be parsed in parallel.\\n *              THIS PATH MUST BE OPTIMISED FOR PERFORMANCE.\\n *\\n*/\\nvoid ohd(int seq,\\n        tapa::istream<sb_apkt_t>& wai_to_ohd_write,\\n        tapa::ostream<sb_apkt_t>& ohd_to_wao_write,\\n        tapa::obuffers<sb_hmsg_t[SB_WORDS_PER_PAGE], (SB_PAGES_PER_XCSR), 1, tapa::array_partition<tapa::block<SB_NUM_PARTITIONS>>, tapa::memcore<tapa::bram>>& backend_pages) {\\n  \\n  bool valid, xfer_ctrl_valid;\\n  bool burst_done = true, rsp_done = true, err_state = false;\\n  sb_dmsg_t msgdata = {0};\\n  sb_portid_t xctrid;\\n  uint8_t nmsgs, pageid, msgs_rxed, last_pageid = 0xFF;\\n  uint16_t start_index = 0;\\n  sb_apkt_t req, rsp;\\n  uint8_t code;\\n  bool last_buffer_released = true;\\n  \\n  OHD_MAIN: for(;;)\\n  {\\n    #pragma HLS latency max=0\\n    valid = wai_to_ohd_write.try_peek(req);   // peek the request stream\\n\\n    if(valid)                                 // this must be a new request\\n    {\\n      code        = req.msg.control.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB);       // get the code\\n      nmsgs       = req.msg.control.range(SB_CMSG_LENGTH_MSB, SB_CMSG_LENGTH_LSB);   // get number of messages to write\\n      start_index = req.msg.control.range(SB_CMSG_ADDR_MSB, SB_CMSG_ADDR_LSB);       // get starting index of where to write to\\n      xctrid      = req.msg.control.range(SB_CMSG_XCXR_MSB, SB_CMSG_XCXR_LSB);       // get the xctrid from xcxr field\\n      pageid      = req.msg.control.range(SB_CMSG_PAGE_MSB, SB_CMSG_PAGE_LSB);       // get the page index\\n      err_state   = (last_buffer_released) ? 0 : (pageid != last_pageid);\\n      rsp.msg.control = req.msg.control;                // store the req ctrl pkt in the rsp ctrl pkt, modify it along the way\\n      assert(pageid < SB_PAGES_PER_XCSR);\\n\\n      if(last_buffer_released)\\n      {\\n        DEBUG_PRINT_OHD_BUFF(\"[OHD][xcsr:%2d][T]: Acquiring Buffer\\\\n\", seq);\\n        auto section = backend_pages[pageid].create_section();\\n        backend_pages[pageid].acquire(section);\\n        last_pageid = pageid;\\n        last_buffer_released = false;\\n      }\\n      else\\n      {\\n        auto& page_ref = (backend_pages[pageid].create_section())();\\n        msgdata = req.msg.std_msg;            // extract the message\\n        uint16_t access_index = 2*start_index;\\n        // write it in the buffer\\n        for(uint16_t i = 0; i < SB_NUM_PARTITIONS; i++)\\n        {\\n          #pragma HLS unroll\\n          #pragma HLS dependence variable=page_ref dependent=false type=intra direction=waw\\n          #pragma HLS dependence variable=page_ref dependent=false type=inter direction=waw\\n          page_ref[i*(SB_WORDS_PER_PAGE/SB_NUM_PARTITIONS) + access_index+0] = (sb_hmsg_t)(msgdata.msg[i] & 0xFFFFFFFF);  // port 1\\n          page_ref[i*(SB_WORDS_PER_PAGE/SB_NUM_PARTITIONS) + access_index+1] = (sb_hmsg_t)(msgdata.msg[i] >> SB_HMSG_W);  // port 2          \\n        }\\n\\n        // set code\\n        rsp.msg.control.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB) = SB_RSP_DONE | code;\\n        // patch back the index of the xcsr\\n        rsp.msg.control.range(SB_CMSG_XCXR_MSB, SB_CMSG_XCXR_LSB) = seq;\\n        // update tag with the xctrid extracted in the burst-prep phase above\\n        rsp.tag       = xctrid;\\n        // try to send response\\n        bool written  = ohd_to_wao_write.try_write(rsp);\\n\\n        if(written)\\n        {\\n          sb_apkt_t nc;\\n          wai_to_ohd_write.try_read(nc);\\n          DEBUG_PRINT_OHD(\"[OHD][xcsr:%2d][W]: xctr: %d, pageid: %d, addr: %d\\\\n\", seq, xctrid, pageid, start_index);\\n          // DEBUG_PRINT_OHD(\"[OHD][xcsr:%2d][W]: Message: %lx\\\\n\", seq, (uint64_t)msgdata.msg[0]);\\n          // DEBUG_PRINT_OHD(\"[OHD][xcsr:%2d][W]: Message: %lx %x %x\\\\n\", seq, (uint64_t)msgdata.msg[0], page_ref[2*(start_index + msgs_rxed)], page_ref[2*(start_index + msgs_rxed)+1]);\\n        }\\n\\n        if(code & SB_RW_CONT_MASK)            // if this is a continued transaction\\n        {                                     // don\\'t release buffer again\\n          // DEBUG_PRINT_OHD(\"[OHD][xcsr:%2d][T]: Continued-write flag set\\\\n\", seq);\\n          last_buffer_released = false;\\n        } else {                              // else release buffer\\n          DEBUG_PRINT_OHD_BUFF(\"[OHD][xcsr:%2d][T]: Releasing Buffer\\\\n\", seq);\\n          (backend_pages[pageid].create_section()).release_section();\\n          last_buffer_released = true;\\n        }\\n      }\\n    }\\n    else {\\n      #ifndef __SYNTHESIS__\\n      if(valid && !ohd_to_wao_write.full())\\n      {\\n        DEBUG_PRINT_OHD(\"[OHD][xcsr:%2d][W]: Bad request: burst_done:%d, rsp_done:%d\\\\n\", seq, burst_done, rsp_done);\\n        DEBUG_PRINT_OHD(\"[OHD][xcsr:%2d][X]: req.c_dn         = %d\\\\n\", seq, (int)req.msg.c_dn);\\n        DEBUG_PRINT_OHD(\"[OHD][xcsr:%2d][X]: req.fields.code  = %x\\\\n\", seq, req.msg.control.range(SB_CMSG_CODE_MSB, SB_CMSG_CODE_LSB));\\n        DEBUG_PRINT_OHD(\"[OHD][xcsr:%2d][X]: req.page         = %d\\\\n\", seq, req.msg.control.range(SB_CMSG_PAGE_MSB, SB_CMSG_PAGE_LSB));\\n        DEBUG_PRINT_OHD(\"[OHD][xcsr:%2d][X]: req.xctr         = %d\\\\n\", seq, req.msg.control.range(SB_CMSG_XCXR_MSB, SB_CMSG_XCXR_LSB));\\n        DEBUG_PRINT_OHD(\"[OHD][xcsr:%2d][X]: req.std_msg      = %lx\\\\n\", seq, req.msg.std_msg);\\n        assert(false);  // must never encounter this scenario\\n      }\\n      #endif  // __SYNTHESIS__\\n    }\\n  }\\n}\\n\\n\\nvoid bandwidth( tapa::mmap<const uint64_t> ivector_values,\\n                tapa::mmap<uint64_t> ovector_timer,\\n                int dummy) {\\n  \\n  tapa::stream<uint64_t> values(\"values\");\\n  tapa::stream<uint64_t> timer(\"timer\");\\n  tapa::stream<bool> trigger_timer(\"trigger_timer\");\\n  tapa::streams<bool, SB_NXCTRS> task2_to_task1(\"task2_to_task1\");\\n\\n  mybuf sb;\\n  constexpr int expr_sb_num_pages = SB_NUM_PAGES;\\n  constexpr int expr_sb_num_xcsrs = SB_NXCSRS;\\n  \\n  tapa::streams<sb_req_t, SB_NXCTRS, SB_BURST_SIZE> sb_rx(\"sb_rxqs\");\\n  tapa::streams<sb_rsp_t, SB_NXCTRS, SB_BURST_SIZE> sb_tx(\"sb_txqs\");\\n  \\n  tapa::streams<uint64_t, SB_NDEBUGQS> debugstreams(\"debug_streams\");\\n  // RQR  <--->  RQP\\n  tapa::streams<sb_std_t, SB_NXCTRS, SB_DQS_DEPTH> rqr_to_drp_read(\"rqr_to_drp_read\");\\n  tapa::streams<sb_std_t, SB_NXCTRS, SB_DQS_DEPTH> rqr_to_drp_write(\"rqr_to_drp_write\");\\n  // RQR  <--->  CRA\\n  tapa::streams<sb_cmsg_t, SB_NXCTRS> rqr_to_crp_grab(\"rqr_to_crp_grab\");\\n  tapa::streams<sb_cmsg_t, SB_NXCTRS> rqr_to_crp_free(\"rqr_to_crp_free\");\\n  // CRP  <--->  RQP\\n  tapa::stream<sb_cmsg_t> crp_to_pgm_grab(\"crp_to_pgm_grab\");\\n  tapa::stream<sb_cmsg_t> crp_to_pgm_free(\"crp_to_pgm_free\");\\n  tapa::stream<sb_cmsg_t> pgm_to_crp_sts(\"pgm_to_crp_sts\");\\n  // CRP  <--->  RSG\\n  tapa::stream<sb_cmsg_t> crp_to_rsg_grab(\"crp_to_rsg_grab\");\\n  tapa::stream<sb_cmsg_t> crp_to_rsg_free(\"crp_to_rsg_free\");\\n  \\n  /// PERFORMANCE CRITICAL STREAMS ///\\n  tapa::streams<sb_std_t, SB_NXCTRS, SB_DRPTORSG_DEPTH> drp_to_rsg_read(\"drp_to_rsg_read\");\\n  tapa::streams<sb_std_t, SB_NXCTRS, SB_DRPTORSG_DEPTH> drp_to_rsg_write(\"drp_to_rsg_write\");\\n  // RQP  <--->  RAI <---> IHD\\n  tapa::streams<sb_apkt_t, kN*(kStageCount + 1), SB_RARBQS_DEPTH> rai_arbqs(\"rai_arbqs\");\\n  // IHD  <--->  RAO <---> RSG\\n  tapa::streams<sb_apkt_t, kN*(kStageCount + 1), SB_RARBQS_DEPTH> rao_arbqs(\"rao_arbqs\");\\n  // RQP  <--->  WAI <---> OHD\\n  tapa::streams<sb_apkt_t, kN*(kStageCount + 1), SB_WARBQS_DEPTH> wai_arbqs(\"wai_arbqs\");\\n  // OHD  <--->  WAO <---> RSG\\n  tapa::streams<sb_apkt_t, kN*(kStageCount + 1), SB_WARBQS_DEPTH> wao_arbqs(\"wao_arbqs\");\\n  \\n  // backend pages\\n  tapa::buffers<ap_uint<256>[32], 8, 1, tapa::array_partition<tapa::block<1>>, tapa::memcore<tapa::bram>> backend_pages;\\n\\n  tapa::task()\\n    .invoke<tapa::detach>(Mmap2Stream64, ivector_values, values, SB_MSGS_PER_PAGE*SB_NUM_PAGES/SB_NXCSRS)\\n    .invoke<tapa::detach>(rqr,\\n            sb_rx,\\n            rqr_to_crp_grab,\\n            rqr_to_crp_free,\\n            rqr_to_drp_read,\\n            rqr_to_drp_write)\\n    .invoke<tapa::detach>(crp,\\n            pgm_to_crp_sts,\\n            crp_to_pgm_free,\\n            crp_to_pgm_grab,\\n            crp_to_rsg_free,\\n            crp_to_rsg_grab,\\n            rqr_to_crp_free,\\n            rqr_to_crp_grab)\\n    .invoke<tapa::detach>(pgm,\\n            crp_to_pgm_grab,\\n            crp_to_pgm_free,\\n            pgm_to_crp_sts)\\n    .invoke<tapa::detach>(drp,\\n            rqr_to_drp_read,\\n            rqr_to_drp_write,\\n            drp_to_rsg_read,\\n            drp_to_rsg_write,\\n            rai_arbqs,\\n            wai_arbqs) \\n    .invoke<tapa::detach, kStageCount>(rai, tapa::seq(), rai_arbqs, rai_arbqs)\\n    .invoke<tapa::detach, kStageCount>(wai, tapa::seq(), wai_arbqs, wai_arbqs)\\n    .invoke<tapa::detach, expr_sb_num_xcsrs>(ihd, tapa::seq(),\\n            rai_arbqs,\\n            rao_arbqs,\\n            backend_pages)\\n    .invoke<tapa::detach, expr_sb_num_xcsrs>(ohd, tapa::seq(),\\n            wai_arbqs,\\n            wao_arbqs,\\n            backend_pages)\\n    .invoke<tapa::detach, kStageCount>(rao, tapa::seq(), rao_arbqs, rao_arbqs)\\n    .invoke<tapa::detach, kStageCount>(wao, tapa::seq(), wao_arbqs, wao_arbqs)\\n    .invoke<tapa::detach>(rsg,\\n            crp_to_rsg_grab,\\n            crp_to_rsg_free,\\n            drp_to_rsg_read,\\n            drp_to_rsg_write,\\n            rao_arbqs,\\n            wao_arbqs,\\n            sb_tx)\\n    .invoke(task1, values, sb_rx, sb_tx, task2_to_task1, trigger_timer)\\n    .invoke<tapa::detach>(task2, sb_rx, sb_tx, task2_to_task1)\\n    .invoke<tapa::detach>(tick_timer, trigger_timer, ovector_timer);\\n}\\n\\n///////////////////////////////////////////////////////////////////////////////\\n'"
}